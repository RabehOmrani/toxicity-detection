{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12500,"databundleVersionId":1375107,"sourceType":"competition"},{"sourceId":8256435,"sourceType":"datasetVersion","datasetId":4899855}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"NJ6MhJYYBCwu","outputId":"8848ffc7-0c03-4d7b-8e90-16bb7b3ca056","executionInfo":{"status":"ok","timestamp":1714222773192,"user_tz":-120,"elapsed":1204,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-04-30T22:48:42.407350Z","iopub.execute_input":"2024-04-30T22:48:42.407641Z","iopub.status.idle":"2024-04-30T22:48:43.442815Z","shell.execute_reply.started":"2024-04-30T22:48:42.407616Z","shell.execute_reply":"2024-04-30T22:48:43.441636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install watermark\n%reload_ext watermark\n%watermark -v -p numpy,pandas,torch,transformers","metadata":{"id":"AJqoaFpVpoM8","outputId":"4d525bc9-fc55-4d18-ccfc-62f23aa84452","executionInfo":{"status":"ok","timestamp":1714222835589,"user_tz":-120,"elapsed":18741,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-05-01T20:00:02.796530Z","iopub.execute_input":"2024-05-01T20:00:02.797195Z","iopub.status.idle":"2024-05-01T20:00:15.848599Z","shell.execute_reply.started":"2024-05-01T20:00:02.797160Z","shell.execute_reply":"2024-05-01T20:00:15.847379Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Collecting watermark\n  Downloading watermark-2.4.3-py2.py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: ipython>=6.0 in /opt/conda/lib/python3.10/site-packages (from watermark) (8.20.0)\nRequirement already satisfied: importlib-metadata>=1.4 in /opt/conda/lib/python3.10/site-packages (from watermark) (6.11.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from watermark) (69.0.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=1.4->watermark) (3.17.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (0.1.6)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (3.0.42)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (2.17.2)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (0.6.2)\nRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (5.9.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.0->watermark) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.0->watermark) (0.2.13)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.0->watermark) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.0->watermark) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.0->watermark) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.0->watermark) (1.16.0)\nDownloading watermark-2.4.3-py2.py3-none-any.whl (7.6 kB)\nInstalling collected packages: watermark\nSuccessfully installed watermark-2.4.3\nPython implementation: CPython\nPython version       : 3.10.13\nIPython version      : 8.20.0\n\nnumpy       : 1.26.4\npandas      : 2.2.2\ntorch       : 2.1.2\ntransformers: 4.39.3\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport datetime\nimport gc\nimport random\nfrom nltk.corpus import stopwords\nimport re\nimport nltk\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport transformers\nfrom transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup","metadata":{"id":"w68CZpOwFoly","executionInfo":{"status":"ok","timestamp":1714222848204,"user_tz":-120,"elapsed":2268,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-04-30T22:49:07.623480Z","iopub.execute_input":"2024-04-30T22:49:07.623858Z","iopub.status.idle":"2024-04-30T22:49:07.631174Z","shell.execute_reply.started":"2024-04-30T22:49:07.623826Z","shell.execute_reply":"2024-04-30T22:49:07.630122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('stopwords')","metadata":{"id":"AVuAKpCETYHr","executionInfo":{"status":"ok","timestamp":1714222853040,"user_tz":-120,"elapsed":717,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"outputId":"90b53896-883f-4ba9-a716-829a8d63a9a7","execution":{"iopub.status.busy":"2024-04-30T22:49:11.777207Z","iopub.execute_input":"2024-04-30T22:49:11.778474Z","iopub.status.idle":"2024-04-30T22:49:11.974745Z","shell.execute_reply.started":"2024-04-30T22:49:11.778434Z","shell.execute_reply":"2024-04-30T22:49:11.973886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv('/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ndata_train.head()","metadata":{"id":"mUKLyKc7I6Qp","outputId":"f9d68f32-7be2-43f6-dbfb-3f795833af14","executionInfo":{"status":"ok","timestamp":1714222863632,"user_tz":-120,"elapsed":7256,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-04-30T22:49:14.697239Z","iopub.execute_input":"2024-04-30T22:49:14.697612Z","iopub.status.idle":"2024-04-30T22:49:38.216122Z","shell.execute_reply.started":"2024-04-30T22:49:14.697585Z","shell.execute_reply":"2024-04-30T22:49:38.215129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)\ndata_train.head(10)[['id', 'target', 'comment_text']]","metadata":{"execution":{"iopub.status.busy":"2024-04-30T22:49:46.026243Z","iopub.execute_input":"2024-04-30T22:49:46.026634Z","iopub.status.idle":"2024-04-30T22:49:46.039823Z","shell.execute_reply.started":"2024-04-30T22:49:46.026604Z","shell.execute_reply":"2024-04-30T22:49:46.038830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.shape","metadata":{"id":"dB2jE6am7Dpo","outputId":"297f7826-5803-4b3f-ffbe-3bdf18b96c15","executionInfo":{"status":"ok","timestamp":1714222868219,"user_tz":-120,"elapsed":766,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-04-30T22:49:50.687239Z","iopub.execute_input":"2024-04-30T22:49:50.687606Z","iopub.status.idle":"2024-04-30T22:49:50.693609Z","shell.execute_reply.started":"2024-04-30T22:49:50.687578Z","shell.execute_reply":"2024-04-30T22:49:50.692677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.info()","metadata":{"id":"VA_wGSLQLKCh","outputId":"467807af-7501-4df0-cdac-f41a3cb13f5d","executionInfo":{"status":"ok","timestamp":1714222873017,"user_tz":-120,"elapsed":667,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-04-30T22:49:53.850448Z","iopub.execute_input":"2024-04-30T22:49:53.850822Z","iopub.status.idle":"2024-04-30T22:49:53.871216Z","shell.execute_reply.started":"2024-04-30T22:49:53.850796Z","shell.execute_reply":"2024-04-30T22:49:53.870261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"vsZ5hg-3KHWM","executionInfo":{"status":"ok","timestamp":1714222906862,"user_tz":-120,"elapsed":515,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"outputId":"468e9b02-0653-4cfc-a065-c4053dc48bbd","execution":{"iopub.status.busy":"2024-04-30T22:50:02.735909Z","iopub.execute_input":"2024-04-30T22:50:02.736299Z","iopub.status.idle":"2024-04-30T22:50:02.769956Z","shell.execute_reply.started":"2024-04-30T22:50:02.736271Z","shell.execute_reply":"2024-04-30T22:50:02.768979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sw = stopwords.words('english')\n\ndef clean_text(text,remove = False):\n\n    text = text.lower()\n\n    text = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n\n    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\",text) #Removing URLs\n\n    html=re.compile(r'<.*?>')\n\n    text = html.sub(r'',text) #Removing html tags\n\n    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n    for p in punctuations:\n        text = text.replace(p,'') #Removing punctuations\n    if remove :\n      text = [word.lower() for word in text.split() if ( word.lower() not in sw ) ]\n    else:\n      text = [word.lower() for word in text.split() ]\n\n    text = \" \".join(text) #removing stopwords\n\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text) #Removing emojis\n\n    return text","metadata":{"id":"oZWyipobTLkU","executionInfo":{"status":"ok","timestamp":1714222918369,"user_tz":-120,"elapsed":589,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-04-30T22:50:05.471157Z","iopub.execute_input":"2024-04-30T22:50:05.471766Z","iopub.status.idle":"2024-04-30T22:50:05.484403Z","shell.execute_reply.started":"2024-04-30T22:50:05.471733Z","shell.execute_reply":"2024-04-30T22:50:05.483374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_text(\"This is https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview\")","metadata":{"id":"UooCtApiTkrC","executionInfo":{"status":"ok","timestamp":1714222925421,"user_tz":-120,"elapsed":771,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"outputId":"33b3193d-e0fb-4a9c-9e99-7dcf759267af","execution":{"iopub.status.busy":"2024-04-30T22:50:10.018466Z","iopub.execute_input":"2024-04-30T22:50:10.018837Z","iopub.status.idle":"2024-04-30T22:50:10.029954Z","shell.execute_reply.started":"2024-04-30T22:50:10.018809Z","shell.execute_reply":"2024-04-30T22:50:10.028992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['target'] = data_train['target'].apply(lambda x : 0 if x < 0.5 else 1)\ndata_train.sample(frac = 1).head(10)[['id','target','comment_text']]","metadata":{"id":"Korm59FhoTNY","executionInfo":{"status":"ok","timestamp":1714222930728,"user_tz":-120,"elapsed":1560,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-04-30T22:50:15.604721Z","iopub.execute_input":"2024-04-30T22:50:15.605083Z","iopub.status.idle":"2024-04-30T22:50:18.148090Z","shell.execute_reply.started":"2024-04-30T22:50:15.605057Z","shell.execute_reply":"2024-04-30T22:50:18.147083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['comment_text'] = data_train['comment_text'].apply(str).apply(lambda x : clean_text(x))","metadata":{"id":"VjKqoiEaVM3S","executionInfo":{"status":"ok","timestamp":1714222953480,"user_tz":-120,"elapsed":19206,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-04-30T22:50:29.901182Z","iopub.execute_input":"2024-04-30T22:50:29.901840Z","iopub.status.idle":"2024-04-30T22:52:45.294204Z","shell.execute_reply.started":"2024-04-30T22:50:29.901808Z","shell.execute_reply":"2024-04-30T22:52:45.293141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set(data_train['target'])","metadata":{"execution":{"iopub.status.busy":"2024-04-30T22:52:52.254659Z","iopub.execute_input":"2024-04-30T22:52:52.255034Z","iopub.status.idle":"2024-04-30T22:52:52.477963Z","shell.execute_reply.started":"2024-04-30T22:52:52.255005Z","shell.execute_reply":"2024-04-30T22:52:52.477048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comments  = data_train['comment_text'].values\nlabels = data_train['target'].apply(int).values","metadata":{"id":"7mWB1PGWV9sm","executionInfo":{"status":"ok","timestamp":1714222973235,"user_tz":-120,"elapsed":526,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-04-30T22:53:05.534498Z","iopub.execute_input":"2024-04-30T22:53:05.534851Z","iopub.status.idle":"2024-04-30T22:53:06.609121Z","shell.execute_reply.started":"2024-04-30T22:53:05.534823Z","shell.execute_reply":"2024-04-30T22:53:06.608331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","metadata":{"id":"iB3CDwwsWTMX","executionInfo":{"status":"ok","timestamp":1714222978666,"user_tz":-120,"elapsed":2474,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"outputId":"be41b6d7-6e25-43a4-8e85-f592f4e4213e","execution":{"iopub.status.busy":"2024-04-30T22:53:15.724339Z","iopub.execute_input":"2024-04-30T22:53:15.724715Z","iopub.status.idle":"2024-04-30T22:53:18.069966Z","shell.execute_reply.started":"2024-04-30T22:53:15.724687Z","shell.execute_reply":"2024-04-30T22:53:18.069023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(' Original: ', comments[0])\n\n\nprint('Tokenized: ', tokenizer.tokenize(comments[0]))\n\n\nprint('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(comments[0])))","metadata":{"id":"SGSEmkzOWa61","executionInfo":{"status":"ok","timestamp":1714222983267,"user_tz":-120,"elapsed":935,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"outputId":"bc1f55cf-82e8-4ef5-8f29-9703499703a6","execution":{"iopub.status.busy":"2024-04-30T22:53:24.956632Z","iopub.execute_input":"2024-04-30T22:53:24.957003Z","iopub.status.idle":"2024-04-30T22:53:24.965069Z","shell.execute_reply.started":"2024-04-30T22:53:24.956973Z","shell.execute_reply":"2024-04-30T22:53:24.964170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 0 # it is 348\nfrom math import log2,floor\n\nfor comment in comments:\n\n    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n    input_ids = tokenizer.encode(comment, add_special_tokens=True)\n\n\n    max_len = max(max_len, len(input_ids))\nmax = 2**(floor(log2(max))+1)\nprint('Max sentence length: ', max_len)","metadata":{"id":"WS49yJXzW1t0","executionInfo":{"status":"ok","timestamp":1714223430423,"user_tz":-120,"elapsed":411402,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"outputId":"4ae2c136-4b86-40e2-e301-918ab4522465","execution":{"iopub.status.busy":"2024-04-30T22:53:28.914343Z","iopub.execute_input":"2024-04-30T22:53:28.914704Z","iopub.status.idle":"2024-04-30T23:51:23.763148Z","shell.execute_reply.started":"2024-04-30T22:53:28.914677Z","shell.execute_reply":"2024-04-30T23:51:23.762182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ninput_ids = []\nattention_masks = []\n\n# Wrap the loop with tqdm\nfor comment in tqdm(comments, desc=\"Processing comments\"):\n    encoded_dict = tokenizer.encode_plus(\n                        comment,\n                        add_special_tokens=True,\n                        max_length=max_len,\n                        pad_to_max_length=True,\n                        return_attention_mask=True,\n                        return_tensors='pt',\n                        truncation=True\n                   )\n\n    input_ids.append(encoded_dict['input_ids'])\n    attention_masks.append(encoded_dict['attention_mask'])\n\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\nlabels = torch.tensor(labels)\n\nprint('Original: ', comments[0])\nprint('Token IDs:', input_ids[0])\n","metadata":{"id":"vPXCNp_8XXL9","executionInfo":{"status":"ok","timestamp":1714223973151,"user_tz":-120,"elapsed":537924,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"outputId":"7494c3a9-809b-48cf-c32a-7ee2c0066096","execution":{"iopub.status.busy":"2024-04-30T23:58:27.401357Z","iopub.execute_input":"2024-04-30T23:58:27.401743Z","iopub.status.idle":"2024-05-01T01:11:08.854928Z","shell.execute_reply.started":"2024-04-30T23:58:27.401716Z","shell.execute_reply":"2024-05-01T01:11:08.853922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndataset = TensorDataset(input_ids, attention_masks, labels)\n\n\ntrain_size = int(0.8 * len(dataset))\n\n\nval_size = len(dataset)  - train_size\n\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint('{:>5,} training samples'.format(train_size))\nprint('{:>5,} validation samples'.format(val_size))","metadata":{"id":"XHT7OJr4ZHb4","executionInfo":{"status":"ok","timestamp":1714224002756,"user_tz":-120,"elapsed":906,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"outputId":"29b4b60e-cc4a-4e8a-8db8-b5cc472df61b","execution":{"iopub.status.busy":"2024-05-01T01:11:20.742274Z","iopub.execute_input":"2024-05-01T01:11:20.743310Z","iopub.status.idle":"2024-05-01T01:11:20.957030Z","shell.execute_reply.started":"2024-05-01T01:11:20.743265Z","shell.execute_reply":"2024-05-01T01:11:20.955920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbatch_size = 28\n\n\ntrain_dataloader = DataLoader(\n            train_dataset,  # The training samples.\n            sampler = RandomSampler(train_dataset), # Select batches randomly\n            batch_size = batch_size # Trains with this batch size.\n        )\n\n# For validation the order doesn't matter, so we'll just read them sequentially.\nvalidation_dataloader = DataLoader(\n            val_dataset, # The validation samples.\n            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","metadata":{"id":"beyDin-0bMHc","executionInfo":{"status":"ok","timestamp":1714224006294,"user_tz":-120,"elapsed":501,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-05-01T01:14:17.632666Z","iopub.execute_input":"2024-05-01T01:14:17.633311Z","iopub.status.idle":"2024-05-01T01:14:17.638763Z","shell.execute_reply.started":"2024-05-01T01:14:17.633280Z","shell.execute_reply":"2024-05-01T01:14:17.637786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\nfree_gpu_cache()                           \n'''","metadata":{"execution":{"iopub.status.busy":"2024-04-28T22:24:28.618242Z","iopub.execute_input":"2024-04-28T22:24:28.618660Z","iopub.status.idle":"2024-04-28T22:24:31.471455Z","shell.execute_reply.started":"2024-04-28T22:24:28.618629Z","shell.execute_reply":"2024-04-28T22:24:31.469970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load BertForSequenceClassification, the pretrained BERT model with a single\n# linear classification layer on top.\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n    num_labels = 2, # The number of output labels--2 for binary classification.\n                    # You can increase this for multi-class tasks.\n    output_attentions = False, # Whether the model returns attentions weights.\n    output_hidden_states = False, # Whether the model returns all hidden-states.\n)\nmodel = model.to(device)","metadata":{"id":"b23UzYR3bPB-","executionInfo":{"status":"ok","timestamp":1714224022435,"user_tz":-120,"elapsed":2216,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"outputId":"23875902-1f5f-47c8-eb62-ac4b80e3d16b","execution":{"iopub.status.busy":"2024-05-01T01:14:27.763459Z","iopub.execute_input":"2024-05-01T01:14:27.763829Z","iopub.status.idle":"2024-05-01T01:14:28.465509Z","shell.execute_reply.started":"2024-05-01T01:14:27.763801Z","shell.execute_reply":"2024-05-01T01:14:28.464701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n                )","metadata":{"id":"e2rXF8Zmbc-v","executionInfo":{"status":"ok","timestamp":1714224030038,"user_tz":-120,"elapsed":3356,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"outputId":"cdf497b6-bd9d-45cf-d807-62ed5a5fb78a","execution":{"iopub.status.busy":"2024-05-01T01:12:10.623177Z","iopub.execute_input":"2024-05-01T01:12:10.624036Z","iopub.status.idle":"2024-05-01T01:12:10.634366Z","shell.execute_reply.started":"2024-05-01T01:12:10.624003Z","shell.execute_reply":"2024-05-01T01:12:10.633339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of training epochs. The BERT authors recommend between 2 and 4.\n# We chose to run for 4, but we'll see later that this may be over-fitting the\n# training data.\nepochs = 3\n\n# Total number of training steps is [number of batches] x [number of epochs].\n# (Note that this is not the same as the number of training samples).\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","metadata":{"id":"EN5uQMSjbird","executionInfo":{"status":"ok","timestamp":1714224034747,"user_tz":-120,"elapsed":7,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-05-01T01:14:35.222300Z","iopub.execute_input":"2024-05-01T01:14:35.223188Z","iopub.status.idle":"2024-05-01T01:14:35.228148Z","shell.execute_reply.started":"2024-05-01T01:14:35.223153Z","shell.execute_reply":"2024-05-01T01:14:35.227250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","metadata":{"id":"UWY8mj5obne4","executionInfo":{"status":"ok","timestamp":1714224046357,"user_tz":-120,"elapsed":1066,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-05-01T01:12:28.834826Z","iopub.execute_input":"2024-05-01T01:12:28.835190Z","iopub.status.idle":"2024-05-01T01:12:28.840120Z","shell.execute_reply.started":"2024-05-01T01:12:28.835160Z","shell.execute_reply":"2024-05-01T01:12:28.839239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"id":"EP-Za0m0bsO1","executionInfo":{"status":"ok","timestamp":1714224049988,"user_tz":-120,"elapsed":996,"user":{"displayName":"Omrani Rabah","userId":"02501866548281722396"}},"execution":{"iopub.status.busy":"2024-05-01T01:12:31.479991Z","iopub.execute_input":"2024-05-01T01:12:31.480375Z","iopub.status.idle":"2024-05-01T01:12:31.487296Z","shell.execute_reply.started":"2024-05-01T01:12:31.480345Z","shell.execute_reply":"2024-05-01T01:12:31.486415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nseed_val = 42\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\ntraining_stats = []\n\ntotal_t0 = time.time()\n\n# Wrap the outer loop with tqdm to monitor epochs\nfor epoch_i in tqdm(range(0, epochs), desc=\"Epochs\"):\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n    t0 = time.time()\n    total_train_loss = 0\n    model.train()\n    # Wrap the inner loop with tqdm to monitor training progress\n    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training Iterations\")):\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        optimizer.zero_grad()\n        output = model(b_input_ids,\n                       token_type_ids=None,\n                       attention_mask=b_input_mask,\n                       labels=b_labels)\n        loss = output.loss\n        total_train_loss += loss.item()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n\n    avg_train_loss = total_train_loss / len(train_dataloader)\n    training_time = format_time(time.time() - t0)\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epoch took: {:}\".format(training_time))\n\n    print(\"\")\n    print(\"Running Validation...\")\n    t0 = time.time()\n    model.eval()\n    total_eval_accuracy = 0\n    best_eval_accuracy = 0\n    total_eval_loss = 0\n    nb_eval_steps = 0\n    for batch in tqdm(validation_dataloader, desc=\"Validation Iterations\"):\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        with torch.no_grad():\n            output= model(b_input_ids,\n                          token_type_ids=None,\n                          attention_mask=b_input_mask,\n                          labels=b_labels)\n        loss = output.loss\n        total_eval_loss += loss.item()\n        logits = output.logits\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        total_eval_accuracy += flat_accuracy(logits, label_ids)\n\n    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n\n    avg_val_loss = total_eval_loss / len(validation_dataloader)\n    validation_time = format_time(time.time() - t0)\n\n    if avg_val_accuracy > best_eval_accuracy:\n        torch.save(model, 'bert_model')\n        best_eval_accuracy = avg_val_accuracy\n\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Valid. Accur.': avg_val_accuracy,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint(\"\")\nprint(\"Training complete!\")\n\nprint(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n","metadata":{"id":"LvA6p733cBZ_","outputId":"9c6501b2-9078-47c2-8b78-6d8bd3523316","execution":{"iopub.status.busy":"2024-05-01T01:14:40.345132Z","iopub.execute_input":"2024-05-01T01:14:40.346009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert the model to a pipeline for easier use\nfrom transformers import TextClassificationPipeline\npipeline = TextClassificationPipeline(model = model,tokenizer = tokenizer)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:58:02.219968Z","iopub.execute_input":"2024-05-01T19:58:02.220381Z","iopub.status.idle":"2024-05-01T19:58:02.229181Z","shell.execute_reply.started":"2024-05-01T19:58:02.220349Z","shell.execute_reply":"2024-05-01T19:58:02.228253Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"pipeline(\"this is so dump\")","metadata":{"execution":{"iopub.status.busy":"2024-05-01T20:16:41.890052Z","iopub.execute_input":"2024-05-01T20:16:41.890721Z","iopub.status.idle":"2024-05-01T20:16:41.944572Z","shell.execute_reply.started":"2024-05-01T20:16:41.890685Z","shell.execute_reply":"2024-05-01T20:16:41.943635Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"[{'label': 'toxic', 'score': 0.9995365142822266}]"},"metadata":{}}]},{"cell_type":"code","source":"pipeline.save_pretrained('my_outputs')","metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:59:15.384871Z","iopub.execute_input":"2024-05-01T19:59:15.385183Z","iopub.status.idle":"2024-05-01T19:59:16.255571Z","shell.execute_reply.started":"2024-05-01T19:59:15.385157Z","shell.execute_reply":"2024-05-01T19:59:16.254764Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"!cat my_outputs/config.json","metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:58:21.860554Z","iopub.execute_input":"2024-05-01T19:58:21.861187Z","iopub.status.idle":"2024-05-01T19:58:22.937568Z","shell.execute_reply.started":"2024-05-01T19:58:21.861153Z","shell.execute_reply":"2024-05-01T19:58:22.936522Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"{\n  \"_name_or_path\": \"my_outputs\",\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"non-toxic\",\n    \"1\": \"toxic\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"non-toxic\": 0,\n    \"toxic\": 1\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"single_label_classification\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.39.3\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip final.zip my_outputs/*","metadata":{"execution":{"iopub.status.busy":"2024-05-01T20:01:19.280892Z","iopub.execute_input":"2024-05-01T20:01:19.281822Z","iopub.status.idle":"2024-05-01T20:01:43.196518Z","shell.execute_reply.started":"2024-05-01T20:01:19.281782Z","shell.execute_reply":"2024-05-01T20:01:43.195380Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"  adding: my_outputs/config.json (deflated 50%)\n  adding: my_outputs/model.safetensors (deflated 7%)\n  adding: my_outputs/special_tokens_map.json (deflated 42%)\n  adding: my_outputs/tokenizer_config.json (deflated 75%)\n  adding: my_outputs/vocab.txt (deflated 53%)\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLinks,FileLink\nFileLink(r'final.zip')","metadata":{"execution":{"iopub.status.busy":"2024-05-01T20:01:53.542455Z","iopub.execute_input":"2024-05-01T20:01:53.542861Z","iopub.status.idle":"2024-05-01T20:01:53.550345Z","shell.execute_reply.started":"2024-05-01T20:01:53.542828Z","shell.execute_reply":"2024-05-01T20:01:53.549361Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/final.zip","text/html":"<a href='final.zip' target='_blank'>final.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"!ls ","metadata":{"execution":{"iopub.status.busy":"2024-05-01T19:35:34.994708Z","iopub.execute_input":"2024-05-01T19:35:34.995616Z","iopub.status.idle":"2024-05-01T19:35:36.048679Z","shell.execute_reply.started":"2024-05-01T19:35:34.995580Z","shell.execute_reply":"2024-05-01T19:35:36.047665Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"cufile.log  state.db\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}